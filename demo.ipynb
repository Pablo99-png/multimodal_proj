{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ff2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelloFaccia import compute_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfbc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /Users/paolocursi/Desktop/multimodal/tinyvit_face_best.pth\n",
      "Weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from modelloFaccia import load,compute_ids\n",
    "model = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f079062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery = compute_ids(K)\n",
    "https://github.com/robmsmt/ASR-Audio-Data-Links?tab=readme-ov-file#:~:text=Voxforge-,Voxforge%20English,-Read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0d5192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VoxForge English dataset...\n",
      "Failed to download dataset. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "\n",
    "# Create directory for dataset\n",
    "dataset_dir = Path(\"voxforge_dataset\")\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# VoxForge English dataset URL\n",
    "url = \"http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/Audio/Main/16kHz_16bit/voxforge_corpus_16khz.tgz\"\n",
    "\n",
    "print(\"Downloading VoxForge English dataset...\")\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Save the file\n",
    "    file_path = dataset_dir / \"voxforge_corpus_16khz.tgz\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"Dataset downloaded to {file_path}\")\n",
    "    \n",
    "    # Extract the archive\n",
    "    print(\"Extracting dataset...\")\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(dataset_dir)\n",
    "    \n",
    "    print(\"Dataset extracted successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download dataset. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89ef2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1479\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1477\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1041\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1040\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1319\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1318\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load a lightweight Whisper model for speech embeddings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m speech_model = \u001b[43mwhisper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtiny\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_speech_embedding\u001b[39m(audio_path, duration=\u001b[32m5\u001b[39m):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    Extract speech embedding from audio file\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m        Speech embedding tensor\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/whisper/__init__.py:137\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, device, download_root, in_memory)\u001b[39m\n\u001b[32m    134\u001b[39m     download_root = os.path.join(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mXDG_CACHE_HOME\u001b[39m\u001b[33m\"\u001b[39m, default), \u001b[33m\"\u001b[39m\u001b[33mwhisper\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     checkpoint_file = \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     alignment_heads = _ALIGNMENT_HEADS[name]\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.isfile(name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/whisper/__init__.py:73\u001b[39m, in \u001b[36m_download\u001b[39m\u001b[34m(url, root, in_memory)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     69\u001b[39m         warnings.warn(\n\u001b[32m     70\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exists, but the SHA256 checksum does not match; re-downloading the file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source, \u001b[38;5;28mopen\u001b[39m(download_target, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m     75\u001b[39m         total=\u001b[38;5;28mint\u001b[39m(source.info().get(\u001b[33m\"\u001b[39m\u001b[33mContent-Length\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m     76\u001b[39m         ncols=\u001b[32m80\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m         unit_divisor=\u001b[32m1024\u001b[39m,\n\u001b[32m     80\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1347\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1344\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1345\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1348\u001b[39m     r = h.getresponse()\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)>"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load a lightweight Whisper model for speech embeddings\n",
    "speech_model = whisper.load_model(\"tiny\")\n",
    "import os, certifi\n",
    "\n",
    "# Point SSL to certifiâ€™s CA bundle\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "def extract_speech_embedding(audio_path, duration=5):\n",
    "    \"\"\"\n",
    "    Extract speech embedding from audio file\n",
    "    Args:\n",
    "        audio_path: Path to audio file\n",
    "        duration: Duration in seconds to extract (default 5s)\n",
    "    Returns:\n",
    "        Speech embedding tensor\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(audio_path, sr=16000, duration=duration)\n",
    "    \n",
    "    # Ensure audio is the right length\n",
    "    if len(audio) < 16000 * duration:\n",
    "        # Pad with zeros if too short\n",
    "        audio = np.pad(audio, (0, 16000 * duration - len(audio)))\n",
    "    else:\n",
    "        # Truncate if too long\n",
    "        audio = audio[:16000 * duration]\n",
    "    \n",
    "    # Convert to tensor\n",
    "    audio_tensor = torch.from_numpy(audio).float()\n",
    "    \n",
    "    # Extract features using Whisper encoder\n",
    "    with torch.no_grad():\n",
    "        # Whisper expects log-mel spectrogram\n",
    "        mel = whisper.log_mel_spectrogram(audio_tensor)\n",
    "        embedding = speech_model.encoder(mel.unsqueeze(0))\n",
    "        \n",
    "    return embedding.mean(dim=1).squeeze(0)  # Average over time dimension\n",
    "\n",
    "print(\"Speech model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:58:47.410 Python[10871:558587] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting face recognition... Press 'q' to quit\n",
      "Unknown person detected for 5.1s. Starting registration...\n",
      "Added new user: NEW_USER_1\n",
      "Recognized: NEW_USER_1 with similarity 1.000\n",
      "Recognized: NEW_USER_1 with similarity 0.998\n",
      "Recognized: NEW_USER_1 with similarity 0.992\n",
      "Recognized: NEW_USER_1 with similarity 0.986\n",
      "Recognized: NEW_USER_1 with similarity 0.976\n",
      "Recognized: NEW_USER_1 with similarity 0.972\n",
      "Recognized: NEW_USER_1 with similarity 0.972\n",
      "Recognized: NEW_USER_1 with similarity 0.969\n",
      "Recognized: NEW_USER_1 with similarity 0.966\n",
      "Recognized: NEW_USER_1 with similarity 0.970\n",
      "Recognized: NEW_USER_1 with similarity 0.967\n",
      "Recognized: NEW_USER_1 with similarity 0.952\n",
      "Recognized: NEW_USER_1 with similarity 0.941\n",
      "Recognized: NEW_USER_1 with similarity 0.919\n",
      "Recognized: NEW_USER_1 with similarity 0.882\n",
      "Recognized: NEW_USER_1 with similarity 0.846\n",
      "Recognized: NEW_USER_1 with similarity 0.780\n",
      "Unknown person detected for 5.3s. Starting registration...\n",
      "Unknown person detected for 5.3s. Starting registration...\n",
      "Added new user: NEW_USER_2\n",
      "Recognized: NEW_USER_2 with similarity 1.000\n",
      "Recognized: NEW_USER_2 with similarity 0.995\n",
      "Recognized: NEW_USER_2 with similarity 0.983\n",
      "Recognized: NEW_USER_2 with similarity 0.972\n",
      "Recognized: NEW_USER_2 with similarity 0.966\n",
      "Recognized: NEW_USER_2 with similarity 0.957\n",
      "Recognized: NEW_USER_2 with similarity 0.952\n",
      "Recognized: NEW_USER_2 with similarity 0.954\n",
      "Recognized: NEW_USER_2 with similarity 0.957\n",
      "Recognized: NEW_USER_2 with similarity 0.956\n",
      "Recognized: NEW_USER_2 with similarity 0.961\n",
      "Recognized: NEW_USER_2 with similarity 0.968\n",
      "Recognized: NEW_USER_2 with similarity 0.971\n",
      "Recognized: NEW_USER_2 with similarity 0.968\n",
      "Recognized: NEW_USER_2 with similarity 0.950\n",
      "Recognized: NEW_USER_2 with similarity 0.920\n",
      "Recognized: NEW_USER_2 with similarity 0.870\n",
      "Recognized: NEW_USER_2 with similarity 0.793\n",
      "Recognized: NEW_USER_1 with similarity 0.741\n",
      "Recognized: NEW_USER_1 with similarity 0.797\n",
      "Recognized: NEW_USER_1 with similarity 0.835\n",
      "Recognized: NEW_USER_1 with similarity 0.847\n",
      "Recognized: NEW_USER_1 with similarity 0.850\n",
      "Recognized: NEW_USER_1 with similarity 0.828\n",
      "Recognized: NEW_USER_1 with similarity 0.819\n",
      "Recognized: NEW_USER_1 with similarity 0.809\n",
      "Recognized: NEW_USER_1 with similarity 0.803\n",
      "Recognized: NEW_USER_1 with similarity 0.804\n",
      "Recognized: NEW_USER_1 with similarity 0.801\n",
      "Recognized: NEW_USER_1 with similarity 0.795\n",
      "Recognized: NEW_USER_1 with similarity 0.786\n",
      "Recognized: NEW_USER_1 with similarity 0.784\n",
      "Recognized: NEW_USER_1 with similarity 0.788\n",
      "Recognized: NEW_USER_1 with similarity 0.796\n",
      "Recognized: NEW_USER_1 with similarity 0.798\n",
      "Recognized: NEW_USER_1 with similarity 0.796\n",
      "Recognized: NEW_USER_1 with similarity 0.791\n",
      "Recognized: NEW_USER_1 with similarity 0.761\n",
      "Recognized: NEW_USER_1 with similarity 0.759\n",
      "Recognized: NEW_USER_1 with similarity 0.744\n",
      "Recognized: NEW_USER_1 with similarity 0.728\n",
      "Recognized: NEW_USER_2 with similarity 0.756\n",
      "Recognized: NEW_USER_2 with similarity 0.829\n",
      "Recognized: NEW_USER_2 with similarity 0.885\n",
      "Recognized: NEW_USER_2 with similarity 0.913\n",
      "Recognized: NEW_USER_2 with similarity 0.932\n",
      "Recognized: NEW_USER_2 with similarity 0.925\n",
      "Recognized: NEW_USER_2 with similarity 0.906\n",
      "Recognized: NEW_USER_2 with similarity 0.891\n",
      "Recognized: NEW_USER_2 with similarity 0.871\n",
      "Recognized: NEW_USER_2 with similarity 0.859\n",
      "Recognized: NEW_USER_2 with similarity 0.846\n",
      "Recognized: NEW_USER_2 with similarity 0.841\n",
      "Recognized: NEW_USER_2 with similarity 0.836\n",
      "Recognized: NEW_USER_2 with similarity 0.822\n",
      "Recognized: NEW_USER_2 with similarity 0.805\n",
      "Recognized: NEW_USER_2 with similarity 0.825\n",
      "Recognized: NEW_USER_2 with similarity 0.830\n",
      "Recognized: NEW_USER_2 with similarity 0.843\n",
      "Recognized: NEW_USER_2 with similarity 0.849\n",
      "Recognized: NEW_USER_2 with similarity 0.863\n",
      "Recognized: NEW_USER_2 with similarity 0.876\n",
      "Recognized: NEW_USER_2 with similarity 0.886\n",
      "Recognized: NEW_USER_2 with similarity 0.867\n",
      "Recognized: NEW_USER_2 with similarity 0.817\n",
      "Recognized: NEW_USER_2 with similarity 0.823\n",
      "Recognized: NEW_USER_2 with similarity 0.828\n",
      "Recognized: NEW_USER_2 with similarity 0.835\n",
      "Recognized: NEW_USER_2 with similarity 0.841\n",
      "Recognized: NEW_USER_2 with similarity 0.847\n",
      "Recognized: NEW_USER_2 with similarity 0.835\n",
      "Recognized: NEW_USER_2 with similarity 0.865\n",
      "Recognized: NEW_USER_2 with similarity 0.869\n",
      "Recognized: NEW_USER_2 with similarity 0.850\n",
      "Recognized: NEW_USER_2 with similarity 0.829\n",
      "Recognized: NEW_USER_2 with similarity 0.738\n",
      "Recognized: NEW_USER_2 with similarity 0.734\n",
      "Recognized: NEW_USER_2 with similarity 0.734\n",
      "Recognized: NEW_USER_2 with similarity 0.779\n",
      "Recognized: NEW_USER_2 with similarity 0.844\n",
      "Recognized: NEW_USER_2 with similarity 0.846\n",
      "Recognized: NEW_USER_2 with similarity 0.816\n",
      "Recognized: NEW_USER_2 with similarity 0.791\n",
      "Recognized: NEW_USER_2 with similarity 0.813\n",
      "Recognized: NEW_USER_2 with similarity 0.820\n",
      "Recognized: NEW_USER_2 with similarity 0.826\n",
      "Recognized: NEW_USER_2 with similarity 0.830\n",
      "Recognized: NEW_USER_2 with similarity 0.842\n",
      "Recognized: NEW_USER_2 with similarity 0.856\n",
      "Recognized: NEW_USER_2 with similarity 0.787\n",
      "Recognized: NEW_USER_2 with similarity 0.795\n",
      "Recognized: NEW_USER_2 with similarity 0.804\n",
      "Recognized: NEW_USER_2 with similarity 0.778\n",
      "Recognized: NEW_USER_2 with similarity 0.711\n",
      "Recognized: NEW_USER_2 with similarity 0.711\n",
      "Recognized: NEW_USER_2 with similarity 0.711\n",
      "Recognized: NEW_USER_2 with similarity 0.701\n",
      "Recognized: NEW_USER_2 with similarity 0.748\n",
      "Recognized: NEW_USER_2 with similarity 0.789\n",
      "Recognized: NEW_USER_2 with similarity 0.790\n",
      "Recognized: NEW_USER_2 with similarity 0.787\n",
      "Recognized: NEW_USER_2 with similarity 0.769\n",
      "Recognized: NEW_USER_2 with similarity 0.740\n",
      "Unknown person detected for 5.3s. Starting registration...\n",
      "Added new user: NEW_USER_3\n",
      "Recognized: NEW_USER_3 with similarity 1.000\n",
      "Recognized: NEW_USER_3 with similarity 0.985\n",
      "Recognized: NEW_USER_3 with similarity 0.940\n",
      "Recognized: NEW_USER_3 with similarity 0.933\n",
      "Recognized: NEW_USER_3 with similarity 0.921\n",
      "Recognized: NEW_USER_3 with similarity 0.908\n",
      "Recognized: NEW_USER_3 with similarity 0.916\n",
      "Recognized: NEW_USER_3 with similarity 0.912\n",
      "Recognized: NEW_USER_3 with similarity 0.916\n",
      "Recognized: NEW_USER_3 with similarity 0.930\n",
      "Recognized: NEW_USER_3 with similarity 0.919\n",
      "Recognized: NEW_USER_3 with similarity 0.913\n",
      "Recognized: NEW_USER_3 with similarity 0.909\n",
      "Recognized: NEW_USER_3 with similarity 0.929\n",
      "Recognized: NEW_USER_3 with similarity 0.920\n",
      "Recognized: NEW_USER_3 with similarity 0.865\n",
      "Recognized: NEW_USER_3 with similarity 0.723\n",
      "Recognized: NEW_USER_1 with similarity 0.720\n",
      "Recognized: NEW_USER_1 with similarity 0.762\n",
      "Recognized: NEW_USER_1 with similarity 0.782\n",
      "Face recognition stopped\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from collections import deque\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Parameters\n",
    "k = K  # Queue size for embeddings\n",
    "alpha = 0.7  # Similarity threshold\n",
    "frame_interval = 5  # Process embeddings every 10 frames\n",
    "unknown_timeout = 5.0  # Seconds before adding new user\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "# Initialize face detector (lightweight)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize embedding queue\n",
    "embedding_queue = deque(maxlen=k)\n",
    "\n",
    "# Frame counter\n",
    "frame_count = 0\n",
    "\n",
    "# Variables to store recognition results\n",
    "current_match = None\n",
    "current_similarity = 0.0\n",
    "\n",
    "# Variables for new user registration\n",
    "unknown_start_time = None\n",
    "registration_mode = False\n",
    "registration_embeddings = deque(maxlen=k)\n",
    "registration_frame_count = 0\n",
    "new_user_counter = 1\n",
    "\n",
    "print(\"Starting face recognition... Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Convert to grayscale for face detection (every frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces (every frame)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        # Take the largest face (assuming closest to camera)\n",
    "        largest_face = max(faces, key=lambda f: f[2] * f[3])\n",
    "        x, y, w, h = largest_face\n",
    "        \n",
    "        # Process embeddings only every 10th frame\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Extract face region with some padding\n",
    "            padding = 20\n",
    "            x1 = max(0, x - padding)\n",
    "            y1 = max(0, y - padding)\n",
    "            x2 = min(frame.shape[1], x + w + padding)\n",
    "            y2 = min(frame.shape[0], y + h + padding)\n",
    "            \n",
    "            face_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if face_img.size > 0:\n",
    "                # Convert to PIL Image and apply transforms\n",
    "                face_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))\n",
    "                face_tensor = val_tfms(face_pil).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get embedding\n",
    "                with torch.no_grad():\n",
    "                    embedding = model(face_tensor, return_embedding=True).squeeze(0)\n",
    "                \n",
    "                # Add to queue (automatically removes oldest if queue is full)\n",
    "                embedding_queue.append(embedding)\n",
    "                \n",
    "                # If in registration mode, also add to registration queue\n",
    "                if registration_mode:\n",
    "                    registration_embeddings.append(embedding)\n",
    "                    registration_frame_count += 1\n",
    "                    \n",
    "                    # If we have enough embeddings for registration\n",
    "                    if len(registration_embeddings) >= k:\n",
    "                        # Compute average embedding for new user\n",
    "                        avg_registration_embedding = torch.stack(list(registration_embeddings)).mean(dim=0)\n",
    "                        \n",
    "                        # Add new user to gallery\n",
    "                        new_user_name = f\"NEW_USER_{new_user_counter}\"\n",
    "                        gallery[new_user_name] = avg_registration_embedding\n",
    "                        new_user_counter += 1\n",
    "                        \n",
    "                        print(f\"Added new user: {new_user_name}\")\n",
    "                        \n",
    "                        # Reset registration mode\n",
    "                        registration_mode = False\n",
    "                        registration_embeddings.clear()\n",
    "                        registration_frame_count = 0\n",
    "                        unknown_start_time = None\n",
    "                \n",
    "                # If we have enough embeddings, compute average and compare\n",
    "                if len(embedding_queue) >= k:\n",
    "                    # Compute average embedding\n",
    "                    avg_embedding = torch.stack(list(embedding_queue)).mean(dim=0)\n",
    "                    \n",
    "                    # Compare with gallery\n",
    "                    best_match = None\n",
    "                    best_similarity = 0.0\n",
    "                    \n",
    "                    for identity_name, embeddings in gallery.items():\n",
    "                        # Compare with both tensors in gallery\n",
    "                        sim = F.cosine_similarity(avg_embedding.unsqueeze(0), embeddings.unsqueeze(0)).item()\n",
    "\n",
    "                        # Take the maximum similarity\n",
    "                        if sim > best_similarity:\n",
    "                            best_similarity = sim\n",
    "                            best_match = identity_name\n",
    "                    \n",
    "                    # Update current recognition results\n",
    "                    current_match = best_match\n",
    "                    current_similarity = best_similarity\n",
    "                    \n",
    "                    if best_similarity > alpha:\n",
    "                        print(f\"Recognized: {best_match} with similarity {best_similarity:.3f}\")\n",
    "                        # Reset unknown timer since we found a match\n",
    "                        unknown_start_time = None\n",
    "                        registration_mode = False\n",
    "                    else:\n",
    "                        # Person is unknown\n",
    "                        if unknown_start_time is None:\n",
    "                            unknown_start_time = current_time\n",
    "                        \n",
    "                        # Check if unknown for long enough and not already in registration mode\n",
    "                        elapsed = current_time - unknown_start_time\n",
    "                        if elapsed >= unknown_timeout and not registration_mode:\n",
    "                            print(f\"Unknown person detected for {elapsed:.1f}s. Starting registration...\")\n",
    "                            registration_mode = True\n",
    "                            registration_embeddings.clear()\n",
    "                            registration_frame_count = 0\n",
    "                \n",
    "                # Clean up\n",
    "                del face_tensor, embedding\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Draw face rectangle (every frame)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display current recognition result (every frame)\n",
    "        if current_match is not None and current_similarity > alpha:\n",
    "            text = f\"{current_match}: {current_similarity:.3f}\"\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 255, 0), 2)\n",
    "        elif current_match is not None:\n",
    "            # Show registration status\n",
    "            if registration_mode:\n",
    "                elapsed = current_time - unknown_start_time if unknown_start_time else 0\n",
    "                text = f\"Registering... ({len(registration_embeddings)}/{k})\"\n",
    "                cv2.putText(frame, text, (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                          0.6, (0, 255, 255), 2)\n",
    "            \n",
    "            text = f\"Unknown: {current_similarity:.3f}\"\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 0, 255), 2)\n",
    "    else:\n",
    "        # No face detected, reset unknown timer\n",
    "        unknown_start_time = None\n",
    "        registration_mode = False\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    \n",
    "    # Break on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Face recognition stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b12c7d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gallery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgallery\u001b[49m.keys()\n",
      "\u001b[31mNameError\u001b[39m: name 'gallery' is not defined"
     ]
    }
   ],
   "source": [
    "gallery.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ac01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
